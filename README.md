# Transformer Encoder-Decoder (PyTorch Educational)

Educational Transformer implementation built from scratch in PyTorch.

## Features

- Pre-norm encoder-decoder architecture
- Multi-head attention with sinusoidal positional embeddings
- Training loop and autoregressive generation example

Built as a learning resource to understand Transformer internals without abstractions (other than PyTorch).

---
_Written without AI assistance._
